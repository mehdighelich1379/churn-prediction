ðŸ“Š Customer Churn Prediction

A machine learning project to predict customer churn using structured data. The goal is to build a reliable model that performs well both on synthetic training data and real-world data with different distributions.

---

ðŸ“ Project Structure
```bash
CUSTOMER_CHURN/
â”œâ”€â”€ data/                   # Raw and preprocessed datasets
â”œâ”€â”€ notebook/               # Exploratory data analysis and model experiments
â”‚   â”œâ”€â”€ EDA_Train_Dataset.ipynb
â”‚   â”œâ”€â”€ EDA_Test_Dataset.ipynb
â”‚   â”œâ”€â”€ build_model.ipynb   # Training multiple models (XGBoost, CatBoost, LightGBM)
â”‚   â””â”€â”€ catboost_info/      # CatBoost logs
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ data/               # (optional submodules for data loading/prep)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train_model.py  # Model training scripts
â”‚   â”‚   â””â”€â”€ XGBClassifier.joblib  # Final saved model (XGBoost)
â”‚   â”œâ”€â”€ utils/              # Utility functions
â”‚   â”‚   â”œâ”€â”€ init.py
â”‚   
â”‚   â”œâ”€â”€ preprocess.py       # Preprocessing logic (used in pipeline)
|   â”œâ”€â”€ main.py
â”œâ”€â”€ README.md               # Project documentation
â”œâ”€â”€ requirments.txt         # Project dependencies


---

âœ… Project Summary

Performed EDA on both synthetic (train_df) and real-world (real_df) datasets using separate notebooks.

Trained and compared three models:

XGBoost

CatBoost

LightGBM


Selected XGBoost as the final model due to its superior performance on real data.

Designed a scikit-learn pipeline to integrate preprocessing and modeling.

Saved the final trained model using joblib.



---

ðŸ›  Workflow Overview

1. Exploratory Data Analysis
Performed in the notebook/ folder separately for both datasets.


2. Model Training & Evaluation

Initial training was done on synthetic data.

Real data had a different distribution, so the model was fine-tuned on 50% of the real dataset.

This improved accuracy on real data while sacrificing some accuracy on the synthetic dataset (acceptable tradeoff).

## ðŸ“Š Evaluation Results

### Confusion Matrix
![Confusion Matrix](image/Confusion_Matrix.png)

### Feature Importances
![Feature Importances](image/feature_importances.png)

### ROC Curve
![ROC Curve](image/Roc_curve.png)


3. Final Model Pipeline

Preprocessing (categorical encoding, scaling)

Model: XGBoost

Saved using joblib for later inference





---

ðŸ”§ Dependencies

In requirments.txt:

pandas>=1.3
numpy>=1.21
scikit-learn>=1.0
xgboost>=1.6
joblib>=1.1

> You can install dependencies via:



pip install -r requirments.txt


---

ðŸš€ How to Run

import joblib
model = joblib.load('src/models/XGBClassifier.joblib')
preds = model.predict(X_new)
